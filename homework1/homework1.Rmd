---
title: true
geometry: margin=2.25cm
output: 
  pdf_document:
    includes:
      keep_tex: yes
      in_header: header.tex
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question1

### (a)
Let $A$ be the event that the lower face of the coin is a head,
$$\Pr(A)=\frac{2\cdot2+2}{2\cdot5}=\frac{3}{5}.$$

### (b)
Let $A$ be the event that the lower face of the coin is a head, $B$ be the event that the coin is showing heads,
<!-- $$\Pr(A\mid B)=\frac{\Pr(B\mid A)\Pr(A)}{\Pr(B)}=\frac{2/4\cdot0.6}{0.6}=0.5.$$ -->
$$\Pr(A\mid B)=\frac{2\cdot2}{2\cdot2+2}=\frac{2}{3}.$$

### (c)
Let $A$ be the event that the lower face of the coin is a head, $B$ be the event that the coin is showing heads again,
$$\Pr(A\mid B)=\frac{4\cdot2}{4\cdot2+2}=\frac{4}{5}.$$

## Question2

The prior distribution of Beta(4,4) is 
$$f_{prior}(p)=\frac{(4+4-1)!}{(4-1)!(4-1)!}p^3(1-p)^3=420p^3(1-p)^3.$$
If $X$ denotes the number of heads out of 10 number of tosses, with the assumption of independence, then
$$X\sim \text{Binomial}(10,p),$$
$$\Pr(X)=\binom{10}{x}p^x(1-p)^{10-x},$$
$$\Pr(X<3)=\sum_{i=0}^2\binom{10}{i}p^i(1-p)^{10-i}=(1-p)^{10}+10p(1-p)^9+45p^2(1-p)^8.$$
The posterior distribution is then
$$f_{post}(p)\propto \Pr(X<3)\cdot f_{prior}=p^3(1-p)^{13}+10p^4(1-p)^{12}+45p^5(1-p)^{11}.$$

```{r ex2}
func <- function(x) {x^3*(1-x)^13+10*x^4*(1-x)^12+45*x^5*(1-x)^11}
C= 1 / integrate(func, 0, 1)$value
func2 <- function(x) {C * func(x)}
curve(func2, from = 0, to = 1, xlab = 'p', ylab = 'posterior density for p')
```

## Question3

We use 95% confidence interval.

For the first test,

```{r ex3.1}
func <- function(x) {
  x ^ 40 * (1 - x) ^ 10
}
C= 1 / integrate(func, 0, 1)$value
l <- qbeta(0.025, 41, 11)
r <- qbeta(0.975, 41, 11)
func2 <- function(x) {C * func(x)}
curve(
  func2,
  from = 0,
  to = 1,
  xlab = 'p',
  ylab = 'posterior density for p'
)
points(l, func2(l))
points(r, func2(r))
lines(c(l, l), c(0, func2(l)), lty = 2)
lines(c(r, r), c(0, func2(r)), lty = 2)
text(l, 0, round(l, 3))
text(r, 0, round(r, 3))
```

Since $p=0.5$ is not in the central credible interval, the data is biased.

For the second test,

```{r ex3.2}
func <- function(x) {
  x ^ 15 * (1 - x) ^ 35
}
C= 1 / integrate(func, 0, 1)$value
l <- qbeta(0.025, 16, 36)
r <- qbeta(0.975, 16, 36)
func2 <- function(x) {C * func(x)}
curve(
  func2,
  from = 0,
  to = 1,
  xlab = 'p',
  ylab = 'posterior density for p'
)
points(l, func2(l))
points(r, func2(r))
lines(c(l, l), c(0, func2(l)), lty = 2)
lines(c(r, r), c(0, func2(r)), lty = 2)
text(l, 0, round(l, 3))
text(r, 0, round(r, 3))
```

Since $p=0.5$ is not in the central credible interval, the data is biased.

## Question4

### (a)

We define the likelihood function $L$ by
$$L(p)=\prod_{i=1}^n p(1-p)^{x_i-1},$$
$$\ln L(p)=n\ln p+\sum_{i=1}^n(x_i-1)\ln(1-p).$$
Maximizing $\ln L(p)$ will also maximize $L(p)$, so we take the first derivative
and set it equal to zero:
$$\frac{d\ln L(p)}{dp}=\frac{n}{p}-\frac{1}{1-p}\sum_{i=1}^n(x_i-1)=0,$$
$$n(1-p)-p\sum_{i=1}^n(x_i-1)=0,$$
$$n-p\sum_{i=1}^nx_i=0,$$
$$\tilde{p}=\frac{1}{\bar{x}}.$$

### (b)

First we need to prove that the invariance property of maximum likelihood can be applied to a non-monotone function $h$. Recall that if $h$ is monotone function, which means $f\to h$ is one to one, so that
$$L(p)=L(h^{-1}(h(p))),$$
are both maximized by $p$, then
$$\tilde{p}=h^{-1}(\widetilde{h(p)}),$$
$$h(\tilde{p})=\widetilde{h(p)}.$$
Now if $h$ is non-monotone function, which means $f\to h$ is many to one, with the same procedure as above, except that we define the inverse mapping function $h^{-1}(x)$ as a one to many mapping, then we may get more than one possible $\tilde{p}$ in
$$\tilde{p}=h^{-1}(\widetilde{h(p)}).$$
However, only one of them is the original $\tilde{p}$, and what's more important, the original $\tilde{p}$ which maximizes $L(p)$ still corresponds to $h(\tilde{p})$, so $h(\tilde{p})=\widetilde{h(p)}$ dosen't change.

With this property, we can simplt get

$$\tilde{q}=\tilde{p}(1-\tilde{p})=\frac{1}{\bar{x}}\cdot\frac{\bar{x}-1}{\bar{x}}=\frac{\bar{x}-1}{\bar{x}^2}.$$

### (c)

$$\hat{p}=\int_0^1 p\cdot p^n(1-p)^{\sum_{i=1}^n(x_i-1)}dp=B\left(n+2,\sum_{i=1}^n(x_i-1)+1\right).$$



